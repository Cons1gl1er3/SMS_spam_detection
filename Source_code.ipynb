{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cons1gl1er3/SMS_spam_detection/blob/main/Source_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJAk9EOxnavi"
      },
      "source": [
        "# **SETTING UP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAYsJl0ErXJz"
      },
      "source": [
        "## **Data retrieving and libraries installing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8JY2dELpY0v",
        "outputId": "dccdc16c-eb24-4581-add9-4d2c78aae16c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
            "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
            "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
            "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 38 (delta 11), reused 16 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (38/38), 332.48 KiB | 3.23 MiB/s, done.\n",
            "From https://github.com/Cons1gl1er3/SMS_spam_detection\n",
            " * [new branch]      main       -> origin/main\n",
            "There is no tracking information for the current branch.\n",
            "Please specify which branch you want to merge with.\n",
            "See git-pull(1) for details.\n",
            "\n",
            "    git pull <remote> <branch>\n",
            "\n",
            "If you wish to set tracking information for this branch you can do so with:\n",
            "\n",
            "    git branch --set-upstream-to=origin/<branch> master\n",
            "\n",
            "Branch 'main' set up to track remote branch 'main' from 'origin'.\n",
            "Switched to a new branch 'main'\n",
            "Branch 'main' set up to track remote branch 'main' from 'origin'.\n"
          ]
        }
      ],
      "source": [
        "# Clone the directory to get the data\n",
        "!git init\n",
        "!git remote add origin https://github.com/Cons1gl1er3/SMS_spam_detection.git\n",
        "!git pull\n",
        "!git checkout main -f\n",
        "!git branch --set-upstream-to origin/main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8Z5DtPwqh4Q"
      },
      "outputs": [],
      "source": [
        "# Uncomment this if you have any uninstalled libraries\n",
        "#!pip install numpy\n",
        "#!pip install matplotlib\n",
        "#!pip install pandas\n",
        "#!pip install sklearn\n",
        "#!pip install nltk\n",
        "#!pip install hyperopt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khzkG7PprkDX"
      },
      "source": [
        "## **Import libraries and data preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duUt4NhlvP0q",
        "outputId": "158984ef-eb66-45f2-add2-c9d92464db4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "# Basic importation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "pd.set_option('display.width', 180)\n",
        "\n",
        "# Validation\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "# Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Preprocessing\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import PorterStemmer\n",
        "from nltk import tokenize\n",
        "import string\n",
        "\n",
        "# Data Transformation\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Train - Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Hyperparameter\n",
        "from hyperopt import tpe, hp, fmin, STATUS_OK, Trials\n",
        "\n",
        "# Data visualization\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6eCfxs8wq_x"
      },
      "outputs": [],
      "source": [
        "# Read in the input\n",
        "data1 = pd.read_csv('/content/spam1.csv', encoding=\"ISO-8859-1\")\n",
        "data2 = pd.read_csv('/content/spam2.csv', encoding=\"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDSLsT7EvxZQ",
        "outputId": "d29c1595-a078-4a99-a025-d971812ab6e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  label_enc\n",
            "0  Go until jurong point, crazy.. Available only ...          0\n",
            "1                      Ok lar... Joking wif u oni...          0\n",
            "2  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
            "3  U dun say so early hor... U c already then say...          0\n",
            "4  Nah I don't think he goes to usf, he lives aro...          0\n"
          ]
        }
      ],
      "source": [
        "# Drop null columns\n",
        "data1.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1, inplace = True)\n",
        "data1.columns = ['labels', 'text']\n",
        "data2 = data2[data2['labels'] == 'spam']\n",
        "data = pd.concat([data1, data2])\n",
        "data['label_enc'] = data['labels'].map({'ham':0,'spam':1})\n",
        "data.drop(['labels'], axis = 1, inplace = True)\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD6Tzvwtngob"
      },
      "source": [
        "# **DATA ANALYZING AND FEATURE EXTRACTION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anNAtcnwGSrc"
      },
      "source": [
        "### **Feature extraction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9QCgxU_5nHr"
      },
      "outputs": [],
      "source": [
        "# Preprocess\n",
        "SW = stopwords.words(\"english\") + ['u', 'Ã¼', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure']\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    \"\"\"\n",
        "    String text in input, remove its punctuation and stopwords.\n",
        "    Return the cleaned text\n",
        "    \"\"\"\n",
        "    text = text.strip()\n",
        "    text = text.lower()\n",
        "\n",
        "    words = tokenize.word_tokenize(text)\n",
        "\n",
        "    ps = PorterStemmer()\n",
        "\n",
        "    filter_words = [ps.stem(word) for word in words if word not in SW and word.isalnum()]\n",
        "\n",
        "    transformed_text = \" \".join(filter_words)\n",
        "\n",
        "    return transformed_text\n",
        "\n",
        "data[\"cleaned text\"] = data[\"text\"].apply(preprocess_text)\n",
        "\n",
        "# Count Vectorizer\n",
        "Vect = CountVectorizer()\n",
        "\n",
        "X_vect = Vect.fit_transform(data[\"cleaned text\"]).toarray()\n",
        "y_vect = data['label_enc']\n",
        "\n",
        "# TF-IDF\n",
        "Tfidf = TfidfVectorizer()\n",
        "X_tfidf = Tfidf.fit_transform(data[\"cleaned text\"]).toarray()\n",
        "y_tfidf = data['label_enc']\n",
        "\n",
        "# Train, test data\n",
        "X, y = data['cleaned text'], data['label_enc']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RfPMyCCtjxV"
      },
      "source": [
        "# **Hyperparameter Tuning**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diS7JEoqMc4g"
      },
      "source": [
        "## **Using Count Vectorizer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmN4E0tVnsZX"
      },
      "source": [
        "### **RANDOM FOREST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0yVUxz5HM7B",
        "outputId": "b9ffa859-7ba9-4c5f-c08b-62d864486a89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|ââââââââââ| 50/50 [53:43<00:00, 64.48s/trial, best loss: -0.984491541136735]\n",
            "Best: {'criterion': 0, 'max_depth': 69.0, 'n_estimators': 84.0}\n"
          ]
        }
      ],
      "source": [
        "# Uncomment the code below to run the hyperparameter function (time consuming)\n",
        "\n",
        "space1 = {\n",
        "    \"n_estimators\": hp.uniformint(\"n_estimators\", 50, 300),\n",
        "    \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
        "    \"max_depth\": hp.uniformint(\"max_depth\", 1, 70)\n",
        "}\n",
        "\n",
        "def hyperparameter_tuning1_vect(params):\n",
        "    clf = RandomForestClassifier(**params, n_jobs=-1)\n",
        "    acc = cross_val_score(clf, X_vect, y_vect, scoring=\"accuracy\").mean()\n",
        "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
        "\n",
        "trials1_vect = Trials()\n",
        "\n",
        "best1_vect = fmin(\n",
        "    fn=hyperparameter_tuning1_vect,\n",
        "    space = space1,\n",
        "    algo=tpe.suggest,\n",
        "    max_evals=50,\n",
        "    trials=trials1_vect\n",
        ")\n",
        "\n",
        "print(\"Best: {}\".format(best1_vect))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZur2GvHsmlZ"
      },
      "outputs": [],
      "source": [
        "Random_Forest_vect = RandomForestClassifier(n_estimators = 84, max_depth = 69, criterion = 'gini', random_state = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gwq-8AhtsRG"
      },
      "source": [
        "### **SUPPORT VECTOR MACHINE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElZnbxwzYyw2",
        "outputId": "ebe283a5-dedc-4b5a-ef1a-7ea7ba5ea881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|ââââââââââ| 50/50 [2:13:39<00:00, 160.40s/trial, best loss: -0.9963598328308554]\n",
            "Best: {'C': 4, 'gamma': 0, 'kernel': 0}\n"
          ]
        }
      ],
      "source": [
        "# Uncomment the code below to run the hyperparameter function (time consuming)\n",
        "space2 = {\n",
        "    \"gamma\": hp.choice(\"gamma\", [0.1, 1, 10, 100, 1000]),\n",
        "    \"kernel\": hp.choice(\"kernel\", [\"rbf\", \"linear\"]),\n",
        "    \"C\": hp.choice(\"C\", [0.1, 1, 10, 100, 1000]),\n",
        "}\n",
        "\n",
        "def hyperparameter_tuning2(params):\n",
        "    clf = SVC(**params)\n",
        "    acc = cross_val_score(clf, X_vect, y_vect, scoring=\"accuracy\", cv=3).mean()\n",
        "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
        "\n",
        "trials2_vect = Trials()\n",
        "\n",
        "best = fmin(\n",
        "    fn=hyperparameter_tuning2,\n",
        "    space = space2,\n",
        "    algo=tpe.suggest,\n",
        "    max_evals=50,\n",
        "    trials=trials2_vect\n",
        ")\n",
        "\n",
        "print(\"Best: {}\".format(best))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LE95-A09ohkz"
      },
      "outputs": [],
      "source": [
        "SVM_vect = SVC(C = 1000, gamma = 0.1, kernel = 'rbf', random_state = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvVR330hMQ_V"
      },
      "source": [
        "### **Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcAEGafptAch",
        "outputId": "d79b3345-46f7-4e6b-ce70-f843330125c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|ââââââââââ| 100/100 [03:45<00:00,  2.25s/trial, best loss: -0.9770525772472615]\n",
            "Best: {'alpha': 1.0159496223076434}\n"
          ]
        }
      ],
      "source": [
        "# Uncomment the code below to run the hyperparameter function (time consuming)\n",
        "space3 = {\n",
        "    \"alpha\": hp.uniform(\"alpha\", 1, 10)\n",
        "}\n",
        "\n",
        "def hyperparameter_tuning3_vect(params):\n",
        "    clf = MultinomialNB(**params)\n",
        "    acc = cross_val_score(clf, X_vect, y_vect, scoring=\"accuracy\", cv=5).mean()\n",
        "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
        "\n",
        "trials3_vect = Trials()\n",
        "\n",
        "best3_vect = fmin(\n",
        "    fn=hyperparameter_tuning3_vect,\n",
        "    space = space3,\n",
        "    algo=tpe.suggest,\n",
        "    max_evals=100,\n",
        "    trials=trials3_vect\n",
        ")\n",
        "\n",
        "print(\"Best: {}\".format(best3_vect))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UY8pNIYVnjh"
      },
      "outputs": [],
      "source": [
        "Naive_Bayes_vect = MultinomialNB(alpha = 3.067289646139944)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uANs8UUNMjZ2"
      },
      "source": [
        "## **Using TF-IDF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfJBIqOSMyVo"
      },
      "source": [
        "### **RANDOM FOREST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LCcOMsHM6Za",
        "outputId": "470ff430-15bc-42c1-d593-33280c8476fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|ââââââââââ| 50/50 [1:21:36<00:00, 97.94s/trial, best loss: -0.9954107660081982] \n",
            "Best: {'criterion': 1, 'max_depth': 99.0, 'n_estimators': 129.0}\n"
          ]
        }
      ],
      "source": [
        "# Uncomment the code below to run the hyperparameter function (time consuming)\n",
        "space1 = {\n",
        "    \"n_estimators\": hp.uniformint(\"n_estimators\", 50, 300),\n",
        "    \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
        "    \"max_depth\": hp.uniformint(\"max_depth\", 1, 100)\n",
        "}\n",
        "\n",
        "def hyperparameter_tuning1_tfidf(params):\n",
        "    clf = RandomForestClassifier(**params, n_jobs=-1)\n",
        "    acc = cross_val_score(clf, X_tfidf, y_tfidf, scoring=\"accuracy\").mean()\n",
        "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
        "\n",
        "trials1_tfidf = Trials()\n",
        "\n",
        "best1_tfidf = fmin(\n",
        "    fn=hyperparameter_tuning1_tfidf,\n",
        "    space = space1,\n",
        "    algo=tpe.suggest,\n",
        "    max_evals=50,\n",
        "    trials=trials1_tfidf\n",
        ")\n",
        "\n",
        "print(\"Best: {}\".format(best1_tfidf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKprlsroaUzO"
      },
      "outputs": [],
      "source": [
        "Random_Forest_tfidf = RandomForestClassifier(criterion='gini', max_depth = 15, n_estimators = 273, random_state = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poKG1X5cwio9"
      },
      "source": [
        "### **Support Vector Machine**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYjvtRvBi685",
        "outputId": "16df6124-3440-4985-8730-8ca84d9d1b40"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 80%|ââââââââ  | 8/10 [52:41<12:18, 369.24s/trial, best loss: -0.9930368224941869]"
          ]
        }
      ],
      "source": [
        "# Uncomment the code below to run the hyperparameter function (time consuming)\n",
        "space2 = {\n",
        "    \"gamma\": hp.choice(\"gamma\", [10, 100, 1000, 10000]),\n",
        "    \"kernel\": hp.choice(\"kernel\", [\"rbf\", \"linear\"]),\n",
        "    \"C\": hp.choice(\"C\", [0.1, 1, 10, 100]),\n",
        "}\n",
        "\n",
        "def hyperparameter_tuning2_tfidf(params):\n",
        "    clf = SVC(**params)\n",
        "    acc = cross_val_score(clf, X_tfidf, y_tfidf, scoring=\"accuracy\", cv=3).mean()\n",
        "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
        "\n",
        "trials2_tfidf = Trials()\n",
        "\n",
        "best2_tfidf = fmin(\n",
        "    fn=hyperparameter_tuning2_tfidf,\n",
        "    space = space2,\n",
        "    algo=tpe.suggest,\n",
        "    max_evals=10,\n",
        "    trials=trials2_tfidf\n",
        ")\n",
        "\n",
        "print(\"Best: {}\".format(best2_tfidf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dZ0WLKYXQ1D"
      },
      "outputs": [],
      "source": [
        "SVM_tfidf = SVC(C = 10, gamma = 1000, kernel = 'linear', random_state = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeYCCncrywWj"
      },
      "source": [
        "### **Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPoMDgjDwpVU"
      },
      "outputs": [],
      "source": [
        "# Uncomment the code below to run the hyperparameter function (time consuming)\n",
        "space3 = {\n",
        "    \"alpha\": hp.uniform(\"alpha\", 1, 10)\n",
        "}\n",
        "\n",
        "def hyperparameter_tuning3_tfidf(params):\n",
        "    clf = MultinomialNB(**params)\n",
        "    acc = cross_val_score(clf, X_tfidf, y_tfidf, scoring=\"accuracy\", cv=5).mean()\n",
        "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
        "\n",
        "trials3_tfidf = Trials()\n",
        "\n",
        "best3_tfidf = fmin(\n",
        "    fn=hyperparameter_tuning3_tfidf,\n",
        "    space = space3,\n",
        "    algo=tpe.suggest,\n",
        "    max_evals=100,\n",
        "    trials=trials3_tfidf\n",
        ")\n",
        "\n",
        "print(\"Best: {}\".format(best3_tfidf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Krp-7MLgapaz"
      },
      "outputs": [],
      "source": [
        "Naive_Bayes_tfidf = MultinomialNB(alpha = 1.0011554126786382)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n08v4XudXo3R"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pngha1-CaDsy"
      },
      "outputs": [],
      "source": [
        "# Final algorithms\n",
        "Random_Forest_vect = RandomForestClassifier(n_estimators = 84, max_depth = 69, criterion = 'gini', random_state = 1)\n",
        "SVM_vect = SVC(C = 1, gamma = 100, kernel = 'linear', random_state = 1)\n",
        "Naive_Bayes_vect = MultinomialNB(alpha = 3.067289646139944)\n",
        "Random_Forest_tfidf = RandomForestClassifier(criterion='gini', max_depth = 15, n_estimators = 273, random_state = 1)\n",
        "SVM_tfidf = SVC(C = 10, gamma = 1000, kernel = 'linear', random_state = 1)\n",
        "Naive_Bayes_tfidf = MultinomialNB(alpha = 1.0011554126786382)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKDn7fN7H3DT"
      },
      "source": [
        "### **Function to train and evaluate the algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiJ_FMMwH2V9"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_model(vectorizer, model):\n",
        "    # Splitting the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 1)\n",
        "\n",
        "    # Feature extraction\n",
        "    X_train_extracted = vectorizer.fit_transform(X_train)\n",
        "    X_test_extracted = vectorizer.transform(X_test)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_extracted, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test_extracted)\n",
        "\n",
        "    # Evaluate the model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    model_results_dict = {\n",
        "                          'f1-score': f1,\n",
        "                          'recall': recall,\n",
        "                          'precision': precision,\n",
        "                          'accuracy': accuracy}\n",
        "\n",
        "    return model_results_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mmz2P_zQX9F1"
      },
      "outputs": [],
      "source": [
        "Random_Forest_vect_results = train_and_evaluate_model(CountVectorizer(), Random_Forest_vect)\n",
        "SVM_vect_results = train_and_evaluate_model(CountVectorizer(), SVM_vect)\n",
        "Naive_Bayes_vect_results = train_and_evaluate_model(CountVectorizer(), Naive_Bayes_vect)\n",
        "Random_Forest_tfidf_results = train_and_evaluate_model(CountVectorizer(), Random_Forest_tfidf)\n",
        "SVM_tfidf_results = train_and_evaluate_model(CountVectorizer(), SVM_tfidf)\n",
        "Naive_Bayes_tfidf_results = train_and_evaluate_model(CountVectorizer(), Naive_Bayes_tfidf)\n",
        "\n",
        "total_results = pd.DataFrame({\n",
        "                              'Random Forest with Count Vectorizer': Random_Forest_vect_results,\n",
        "                              'Support Vector Machine with Count Vectorizer': SVM_vect_results,\n",
        "                              'Naive Bayes with Count Vectorizer': Naive_Bayes_vect_results,\n",
        "                             'Random Forest with TFIDF': Random_Forest_tfidf_results,\n",
        "                             'Support Vector Machine with TFIDF': SVM_tfidf_results,\n",
        "                             'Naive Bayes with TFIDF': Naive_Bayes_tfidf_results}\n",
        "                             ).transpose().sort_values(['f1-score', 'recall'], ascending=False)\n",
        "\n",
        "print(total_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaEZWm9yy1CZ"
      },
      "outputs": [],
      "source": [
        "# Plotting the result\n",
        "Name = ['RF_vect', 'SVM_vect', 'NB_vect', 'RF_tfidf', 'SVM_tfidf', 'NB_tfidf']\n",
        "f, ax = plt.subplots(1, figsize=(12,5))\n",
        "plt.plot(Name, total_results)\n",
        "plt.legend([\"f1-score\", \"recall\", \"precision\", 'accuracy'], loc =\"lower left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRO2dAt6ayT5"
      },
      "outputs": [],
      "source": [
        "X = Vect.fit_transform(X)\n",
        "SVM_vect.fit(X, y)\n",
        "mes = pd.Series([input()])\n",
        "mes = mes.apply(preprocess_text)\n",
        "mes = Vect.transform(mes).toarray()\n",
        "SVM_vect.predict(mes)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}